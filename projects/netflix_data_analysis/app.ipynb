{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "from dotenv import load_dotenv\n",
    "from langchain_openai import ChatOpenAI\n",
    "import pandas as pd\n",
    "from langgraph.graph import StateGraph,START,END\n",
    "from langchain_core.messages import HumanMessage\n",
    "from pydantic import BaseModel\n",
    "from typing import List\n",
    "\n",
    "load_dotenv()\n",
    "llm = ChatOpenAI(model=\"gpt-4o-mini\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "movie_data_set = pd.read_csv('./sample_100mb.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class DataState(BaseModel):\n",
    "    user_query : str\n",
    "    columns : List[str]\n",
    "    dataset_info : str\n",
    "    dataset_name : str\n",
    "    response : str\n",
    "    error_message : str\n",
    "\n",
    "\n",
    "# df.head().to_string(index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def process_user_query(state:DataState):\n",
    "    return f\"\"\" You are an AI assistant for data analysis. The dataset has following columns : {state['columns']}.\n",
    "    And data looks like this : {state['dataset_info']}.And the name of the dataset is : {state['dataset_name']}\n",
    "    Given the user query : {state['user_query']}, generate the python code to execute the query on the dataset.\n",
    "    \"\"\"\n",
    "def generate_error_prompt(state:DataState):\n",
    "    return f\"\"\"\n",
    "    The generated code caused the following error: {state['error_message']}.\n",
    "    Please rectify the error and regenerate the correct Python code for the query: \"{state['user_query']}\".\n",
    "    \"\"\"\n",
    "    \n",
    "def generate_llm_response(state : DataState):\n",
    "    response = llm.invoke({\"role\":\"user\",\"query\":HumanMessage(content=process_user_query(state=state))})\n",
    "    print(\"response\")\n",
    "    return {state['response']:response}\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def fail_condition(state:DataState):\n",
    "    pass\n",
    "\n",
    "def execute_query(state:DataState):\n",
    "    local_vars = {\"movie_df\": movie_data_set}\n",
    "    try: \n",
    "        exec(state['response'])\n",
    "    except Exception as e:\n",
    "        print(\"LLm Response :\",state['response'] ,\"\\n\\n\")\n",
    "        print(\"Error : \", e)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "new_env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
