{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<center>\n",
    "<h3>Agents Example(creating custom agents)</h3>\n",
    "<h4>Below we can see the example that how agents help LLM to call the tools</h4>\n",
    "</center>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Agents\n",
    "\n",
    "<p>By themselves language model can't take actions- they just ouput text</p>\n",
    "<p>Agents are system that use LLM as a reasoning engine to determine which action to take(means which tool should be called.) and what the input to those actions should be. The result of those action can be feed back into the agent and it determine whether more actions are needed or whether it is okay to finish.</p>\n",
    "\n",
    "<p><code>LangGraph</code> is used to create highly controllable and cutomizable agents</p>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langgraph.graph import START,END,StateGraph #for graph\n",
    "from langchain_core.tools import BaseTool # for tools \n",
    "from pydantic import BaseModel,Field # for type\n",
    "from typing import Optional,Type,Literal,TypedDict\n",
    "from langchain_core.callbacks import CallbackManagerForToolRun,AsyncCallbackManagerForToolRun\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Tool using BaseTool"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "class BaseInputType(BaseModel):\n",
    "    a : int = Field(\"First Number\")\n",
    "    b: int = Field(\"Second Number\")\n",
    "\n",
    "class BaseOutputType(BaseModel):\n",
    "    c : int = Field(\"Result\")\n",
    "    \n",
    "# Tool Implementation\n",
    "\n",
    "# Note: It's important that every field has type hints. BaseTool is a\n",
    "# Pydantic class and not having type hints can lead to unexpected behavior.\n",
    "\n",
    "class SimpleCalculator(BaseTool):\n",
    "    name : str = \"Simple Calculator\"\n",
    "    description : str = \"Helpful for simple math question\"\n",
    "    args_schema: Type[BaseModel] = BaseInputType\n",
    "    return_direct:bool = True\n",
    "    \n",
    "    \n",
    "    # for normal calls\n",
    "    def _run(self,a : int,b:int,run_manager:Optional[CallbackManagerForToolRun] = None) -> BaseOutputType:\n",
    "        return a*b\n",
    "    \n",
    "    # If the calculation is cheap, you can just delegate to the sync implementation\n",
    "    # as shown below.\n",
    "    # If the sync calculation is expensive, you should delete the entire _arun method.\n",
    "    # LangChain will automatically provide a better implementation that will\n",
    "    # kick off the task in a thread to make sure it doesn't block other async code. \n",
    "        \n",
    "    # for async calls\n",
    "    async def _arun(self,a:int,b:int, run_manager:Optional[AsyncCallbackManagerForToolRun] = None)->BaseOutputType:\n",
    "        return self._run(a,b,run_manager)\n",
    "\n",
    "# checking the tool\n",
    "multiply = SimpleCalculator()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Simple Calculator\n",
      "Helpful for simple math question\n",
      "<class '__main__.BaseInputType'>\n"
     ]
    }
   ],
   "source": [
    "print(multiply.name)\n",
    "print(multiply.description)\n",
    "print(multiply.args_schema)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "6\n",
      "625\n"
     ]
    }
   ],
   "source": [
    "print(multiply.invoke({\"a\":2,\"b\":3}))\n",
    "print(await multiply.ainvoke({\"a\":25,\"b\":25}))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### <font style=\"color:green\">Simple agent  implementation using LangGraph</font>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Type of state\n",
    "class State(TypedDict):\n",
    "    first_num : int\n",
    "    sec_num : int\n",
    "    result : int\n",
    "\n",
    "# Defining the functionality of Node\n",
    "def node_1(state):\n",
    "    # let's update the state in node 1\n",
    "    print(\"--- Inside Node 1 (Updating the state) ---- \\n\")\n",
    "    print(\"State : \",state,\"\\n\")\n",
    "    return ({\"first_num\" : state[\"first_num\"], \"sec_num\":state[\"sec_num\"]})\n",
    "\n",
    "def node_2(state):\n",
    "    print(\"---- Inside Node 2 (returning multiply) ----\\n\")\n",
    "    return({\"result\":state[\"first_num\"] * state[\"sec_num\"]})\n",
    "\n",
    "def node_3(state):\n",
    "    print(\"---- Inside node 3 (returning addition) ----\\n\")\n",
    "    return({\"result\" : state[\"first_num\"] + state[\"sec_num\"]})\n",
    "\n",
    "def deciding_node(state)-> Literal[\"node_2\",\"node_3\"]:\n",
    "    if state[\"first_num\"] < state[\"sec_num\"]:\n",
    "        return \"node_2\"\n",
    "    return \"node_3\"\n",
    "\n",
    "# Creating Graph\n",
    "builder = StateGraph(State)\n",
    "\n",
    "# Adding node to graph\n",
    "builder.add_node(\"node_1\",node_1)\n",
    "builder.add_node(\"node_2\",node_2)\n",
    "builder.add_node(\"node_3\",node_3)\n",
    "\n",
    "# Adding edge between graph\n",
    "builder.add_edge(START,\"node_1\")\n",
    "builder.add_conditional_edges(\"node_1\",deciding_node)\n",
    "builder.add_edge(\"node_2\",END)\n",
    "builder.add_edge(\"node_3\",END)\n",
    "\n",
    "# at last compiling the graph\n",
    "graph = builder.compile()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- Inside Node 1 (Updating the state) ---- \n",
      "\n",
      "State :  {'first_num': 10, 'sec_num': 30} \n",
      "\n",
      "---- Inside Node 2 (returning multiply) ----\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'first_num': 10, 'sec_num': 30, 'result': 300}"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "graph.invoke({\"first_num\":10,\"sec_num\":30})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- Inside Node 1 (Updating the state) ---- \n",
      "\n",
      "State :  {'first_num': 100, 'sec_num': 30} \n",
      "\n",
      "---- Inside node 3 (returning addition) ----\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'first_num': 100, 'sec_num': 30, 'result': 130}"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "graph.invoke({\"first_num\":100,\"sec_num\":30})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### <code><strong>Exmaple of 4 key concept using agent</strong></code>\n",
    "<ul>\n",
    "<li>Using <code>Chat message</code> in our graph</li>\n",
    "<li>using <code>Chat Models </code></li>\n",
    "<li><code>Binding tools</code> to LLM</li>\n",
    "<li>Executing <code>toolcall</code> in graph</li>\n",
    "</ul>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Message\n",
    "--desc-- chain timestamp : 0.31"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "==================================\u001b[1m Ai Message \u001b[0m==================================\n",
      "Name: model\n",
      "\n",
      "So you said you were searching ocean manmals?\n",
      "None\n",
      "================================\u001b[1m Human Message \u001b[0m=================================\n",
      "Name: user\n",
      "\n",
      "Yes that's right.\n",
      "None\n",
      "==================================\u001b[1m Ai Message \u001b[0m==================================\n",
      "Name: model\n",
      "\n",
      "Great, what would you like to learn about\n",
      "None\n",
      "================================\u001b[1m Human Message \u001b[0m=================================\n",
      "Name: user\n",
      "\n",
      "I want to learn about the whale in ocean\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "from pprint import pprint\n",
    "from langchain_core.messages import AIMessage,HumanMessage,SystemMessage\n",
    "messages = [AIMessage(content=\"So you said you were searching ocean manmals?\",role=\"model\",name=\"model\")]\n",
    "messages.extend([HumanMessage(content=\"Yes that's right.\", role=\"user\",name=\"user\")])\n",
    "messages.extend([AIMessage(content=\"Great, what would you like to learn about\", role=\"model\",name=\"model\")])\n",
    "messages.extend([HumanMessage(content=\"I want to learn about the whale in ocean\",role=\"user\",name=\"user\")])\n",
    "\n",
    "for m in messages:\n",
    "    print(m.pretty_print())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Chat Models\n",
    "--desc 1.03"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "str"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from langchain_community.llms.ollama import Ollama\n",
    "llm = Ollama(model=\"llama3.1\")\n",
    "result = llm.invoke(messages)\n",
    "type(result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "There are so many fascinating things about whales.\n",
      "\n",
      "Let's dive into it (pun intended). Whales are massive marine mammals that belong to the order Cetacea. There are two suborders: toothed whales (Odontoceti) and baleen whales (Mysticeti).\n",
      "\n",
      "Toothed whales include dolphins, porpoises, and sperm whales. They have a highly developed sense of hearing and echolocation, which helps them navigate and hunt in the dark depths of the ocean.\n",
      "\n",
      "Baleen whales, on the other hand, are filter feeders that use their baleen plates to strain tiny crustaceans, plankton, and small fish from the water. The largest animal to have ever existed on Earth is a blue whale, which can grow up to 100 feet (30 meters) in length and weigh around 200 tons!\n",
      "\n",
      "Some interesting facts about whales include:\n",
      "\n",
      "* Whales are highly social creatures that often live in groups called pods.\n",
      "* They are incredibly intelligent animals that have been observed using complex behaviors like cooperative hunting and even playing.\n",
      "* Some species of whales migrate thousands of miles each year to reach their breeding grounds.\n",
      "* Whales have a unique communication system that involves clicks, whistles, and moans.\n",
      "\n",
      "Which aspect of whales would you like to learn more about? Their behavior, habitat, or perhaps something else?\n"
     ]
    }
   ],
   "source": [
    "print(result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Implement tool yo give below capability TODO"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "I'm happy to help, but I don't have real-time access to your current date and time. However, I can suggest a few options:\n",
      "\n",
      "1. **Check your phone or computer**: Take a look at the clock on your device to see the current date.\n",
      "2. **Use an online calendar**: Websites like Google Calendar, Apple Calendar, or any other digital calendar you might use should be able to tell you the day of the week and date.\n",
      "3. **Ask me about general information**: If you're looking for something specific (e.g., today's weather forecast), feel free to ask!\n",
      "\n",
      "Which option sounds most convenient for you?\n"
     ]
    }
   ],
   "source": [
    "print(llm.invoke([HumanMessage(content=\"what's the day today\",role=\"user\")]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Tools\n",
    "---dec 1.32"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_openai import ChatOpenAI\n",
    "from dotenv import load_dotenv\n",
    "# API keys and Lang Smith \n",
    "import os\n",
    "load_dotenv()\n",
    "os.environ[\"OPENAI_API_KEY\"] = os.getenv(\"OPENAI_API_KEY\")\n",
    "llm = ChatOpenAI(model=\"gpt-4o-mini\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_core.tools import Tool\n",
    "from langchain_core.tools import tool\n",
    "\n",
    "@tool\n",
    "def multiply(a : int,b:int) -> int:\n",
    "    \"\"\"Add two integers.\n",
    "\n",
    "    Args:\n",
    "        a: First integer\n",
    "        b: Second integer\n",
    "    \"\"\"\n",
    "    return a*b\n",
    "\n",
    "# Bind the tool to the LLM\n",
    "llm_with_tool = llm.bind_tools([multiply])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "query = \"What is 3 * 12?\"\n",
    "\n",
    "ai_message = llm_with_tool.invoke(query)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "content='' additional_kwargs={'tool_calls': [{'id': 'call_XysdXilX82HhY4Tsg6mCnC78', 'function': {'arguments': '{\"a\":3,\"b\":12}', 'name': 'multiply'}, 'type': 'function'}], 'refusal': None} response_metadata={'token_usage': {'completion_tokens': 17, 'prompt_tokens': 65, 'total_tokens': 82, 'prompt_tokens_details': {'cached_tokens': 0}, 'completion_tokens_details': {'reasoning_tokens': 0}}, 'model_name': 'gpt-4o-mini-2024-07-18', 'system_fingerprint': 'fp_e2bde53e6e', 'finish_reason': 'tool_calls', 'logprobs': None} id='run-1ac203e1-161c-46b9-8435-da4322c61f88-0' tool_calls=[{'name': 'multiply', 'args': {'a': 3, 'b': 12}, 'id': 'call_XysdXilX82HhY4Tsg6mCnC78', 'type': 'tool_call'}] usage_metadata={'input_tokens': 65, 'output_tokens': 17, 'total_tokens': 82}\n"
     ]
    }
   ],
   "source": [
    "print(ai_message)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'name': 'multiply',\n",
       " 'args': {'a': 3, 'b': 12},\n",
       " 'id': 'call_XysdXilX82HhY4Tsg6mCnC78',\n",
       " 'type': 'tool_call'}"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ai_msg = ai_message\n",
    "ai_msg.tool_calls[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "AIMessage(content='', additional_kwargs={'tool_calls': [{'id': 'call_XysdXilX82HhY4Tsg6mCnC78', 'function': {'arguments': '{\"a\":3,\"b\":12}', 'name': 'multiply'}, 'type': 'function'}], 'refusal': None}, response_metadata={'token_usage': {'completion_tokens': 17, 'prompt_tokens': 65, 'total_tokens': 82, 'prompt_tokens_details': {'cached_tokens': 0}, 'completion_tokens_details': {'reasoning_tokens': 0}}, 'model_name': 'gpt-4o-mini-2024-07-18', 'system_fingerprint': 'fp_e2bde53e6e', 'finish_reason': 'tool_calls', 'logprobs': None}, id='run-1ac203e1-161c-46b9-8435-da4322c61f88-0', tool_calls=[{'name': 'multiply', 'args': {'a': 3, 'b': 12}, 'id': 'call_XysdXilX82HhY4Tsg6mCnC78', 'type': 'tool_call'}], usage_metadata={'input_tokens': 65, 'output_tokens': 17, 'total_tokens': 82})"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ai_msg"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Binding Tool to LLM(use ChatOpenAI model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_openai import ChatOpenAI\n",
    "llm = ChatOpenAI(model=\"gpt-4o-mini\")\n",
    "toolkit= [] # list of tools\n",
    "llm_tool = llm.bind_tools(toolkit)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Calling Tools when LLM needs it"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from IPython.display import display,Image\n",
    "from langgraph.graph.message import MessagesState\n",
    "from langgraph.prebuilt import ToolNode, tools_condition\n",
    "from langgraph.graph import START,StateGraph\n",
    "from langchain_openai import ChatOpenAI\n",
    "from langchain_core.messages import HumanMessage,SystemMessage\n",
    "from pprint import pprint\n",
    "from dotenv import load_dotenv\n",
    "\n",
    "load_dotenv()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/jpeg": "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",
      "text/plain": [
       "<IPython.core.display.Image object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# tools\n",
    "def add(a:int,b:int)-> int:\n",
    "    \"\"\"Help To add two numbers\n",
    "\n",
    "    Args:\n",
    "        a : First Number\n",
    "        b : Second Number\n",
    "\n",
    "    Returns:\n",
    "        int : Result Output\n",
    "    \"\"\"\n",
    "    return a+b\n",
    "\n",
    "def multiply(a:int,b:int)-> int:\n",
    "    \"\"\"Help To multiply two numbers\n",
    "\n",
    "    Args:\n",
    "        a : First Number\n",
    "        b : Second Number\n",
    "\n",
    "    Returns:\n",
    "        int : Result Output\n",
    "    \"\"\"\n",
    "    return a*b\n",
    "llm = ChatOpenAI(model=\"gpt-4o-mini\")\n",
    "llm_tools = llm.bind_tools([add,multiply])\n",
    "\n",
    "\n",
    "# node\n",
    "def call_tool_or_reponse_to_user_by_llm(state:MessagesState):\n",
    "    return {\"messages\":[llm_tools.invoke(state['messages'])]}  # here deciosion will be taken place wether to call the tool or reponse directly to the user\n",
    "\n",
    "builder = StateGraph(MessagesState)\n",
    "builder.add_node(\"call_tool_or_reponse_to_user_by_llm\",call_tool_or_reponse_to_user_by_llm)\n",
    "builder.add_node(\"tools\",ToolNode([add,multiply]))\n",
    "\n",
    "builder.add_edge(START,\"call_tool_or_reponse_to_user_by_llm\")\n",
    "builder.add_conditional_edges(\"call_tool_or_reponse_to_user_by_llm\",tools_condition) # routing between \"__end__\" or \"tools call\"\n",
    "builder.add_edge(\"tools\",\"call_tool_or_reponse_to_user_by_llm\")\n",
    "\n",
    "graph = builder.compile()\n",
    "display(Image(graph.get_graph().draw_mermaid_png()))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def display_message(response):\n",
    "    for message in response['messages']:\n",
    "        print(message.pretty_print())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "query = \"Hey How are you doing?\"\n",
    "response = graph.invoke({\"messages\":HumanMessage(content=query,role = 'user')})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'messages': [HumanMessage(content='Hey How are you doing?', additional_kwargs={}, response_metadata={}, id='c68e4804-2db4-459a-a029-6edeac0e7c37', role='user'),\n",
       "  AIMessage(content=\"I'm just a program, so I don't have feelings, but I'm here and ready to help you! How can I assist you today?\", additional_kwargs={'refusal': None}, response_metadata={'token_usage': {'completion_tokens': 28, 'prompt_tokens': 89, 'total_tokens': 117, 'completion_tokens_details': {'audio_tokens': None, 'reasoning_tokens': 0}, 'prompt_tokens_details': {'audio_tokens': None, 'cached_tokens': 0}}, 'model_name': 'gpt-4o-mini-2024-07-18', 'system_fingerprint': 'fp_e2bde53e6e', 'finish_reason': 'stop', 'logprobs': None}, id='run-eddeb042-1ef2-497c-b9f2-03ea7a458ba5-0', usage_metadata={'input_tokens': 89, 'output_tokens': 28, 'total_tokens': 117, 'input_token_details': {'cache_read': 0}, 'output_token_details': {'reasoning': 0}})]}"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "response"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "================================\u001b[1m Human Message \u001b[0m=================================\n",
      "\n",
      "Hey How are you doing?\n",
      "None\n",
      "==================================\u001b[1m Ai Message \u001b[0m==================================\n",
      "\n",
      "I'm just a program, so I don't have feelings, but I'm here and ready to help you! How can I assist you today?\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "display_message(response)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "query = \"what is 2 multiply by 2\"\n",
    "response1 = graph.invoke({\"messages\":HumanMessage(content=query,role = 'user')})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'messages': [HumanMessage(content='what is 2 multiply by 2', additional_kwargs={}, response_metadata={}, id='704d73d5-6f5d-4004-97c6-8c415cab9dd3', role='user'),\n",
       "  AIMessage(content='', additional_kwargs={'tool_calls': [{'id': 'call_DDPTpQUs25jXqecW6D2tA3WI', 'function': {'arguments': '{\"a\":2,\"b\":2}', 'name': 'multiply'}, 'type': 'function'}], 'refusal': None}, response_metadata={'token_usage': {'completion_tokens': 17, 'prompt_tokens': 91, 'total_tokens': 108, 'completion_tokens_details': {'audio_tokens': None, 'reasoning_tokens': 0}, 'prompt_tokens_details': {'audio_tokens': None, 'cached_tokens': 0}}, 'model_name': 'gpt-4o-mini-2024-07-18', 'system_fingerprint': 'fp_e2bde53e6e', 'finish_reason': 'tool_calls', 'logprobs': None}, id='run-5ca85a91-6e8a-46f7-a2a7-36ebed3695d6-0', tool_calls=[{'name': 'multiply', 'args': {'a': 2, 'b': 2}, 'id': 'call_DDPTpQUs25jXqecW6D2tA3WI', 'type': 'tool_call'}], usage_metadata={'input_tokens': 91, 'output_tokens': 17, 'total_tokens': 108, 'input_token_details': {'cache_read': 0}, 'output_token_details': {'reasoning': 0}}),\n",
       "  ToolMessage(content='4', name='multiply', id='6fef9aec-e9ed-41df-885d-41fb20c46927', tool_call_id='call_DDPTpQUs25jXqecW6D2tA3WI'),\n",
       "  AIMessage(content='2 multiplied by 2 equals 4.', additional_kwargs={'refusal': None}, response_metadata={'token_usage': {'completion_tokens': 10, 'prompt_tokens': 116, 'total_tokens': 126, 'completion_tokens_details': {'audio_tokens': None, 'reasoning_tokens': 0}, 'prompt_tokens_details': {'audio_tokens': None, 'cached_tokens': 0}}, 'model_name': 'gpt-4o-mini-2024-07-18', 'system_fingerprint': 'fp_e2bde53e6e', 'finish_reason': 'stop', 'logprobs': None}, id='run-6932a21a-1159-4074-94d8-6f52f8843b00-0', usage_metadata={'input_tokens': 116, 'output_tokens': 10, 'total_tokens': 126, 'input_token_details': {'cache_read': 0}, 'output_token_details': {'reasoning': 0}})]}"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "response1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "================================\u001b[1m Human Message \u001b[0m=================================\n",
      "\n",
      "what is 2 multiply by 2\n",
      "None\n",
      "==================================\u001b[1m Ai Message \u001b[0m==================================\n",
      "Tool Calls:\n",
      "  multiply (call_DDPTpQUs25jXqecW6D2tA3WI)\n",
      " Call ID: call_DDPTpQUs25jXqecW6D2tA3WI\n",
      "  Args:\n",
      "    a: 2\n",
      "    b: 2\n",
      "None\n",
      "=================================\u001b[1m Tool Message \u001b[0m=================================\n",
      "Name: multiply\n",
      "\n",
      "4\n",
      "None\n",
      "==================================\u001b[1m Ai Message \u001b[0m==================================\n",
      "\n",
      "2 multiplied by 2 equals 4.\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "display_message(response1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "query = \"what is 2 +  2\"\n",
    "response2 = graph.invoke({\"messages\":HumanMessage(content=query,role = 'user')})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'messages': [HumanMessage(content='what is 2 +  2', additional_kwargs={}, response_metadata={}, id='a65d029a-bc07-49bf-9700-f1aef31caf8c', role='user'),\n",
       "  AIMessage(content='', additional_kwargs={'tool_calls': [{'id': 'call_SnoZ1WRbaOtflTq1OYwWAzNf', 'function': {'arguments': '{\"a\":2,\"b\":2}', 'name': 'add'}, 'type': 'function'}], 'refusal': None}, response_metadata={'token_usage': {'completion_tokens': 17, 'prompt_tokens': 91, 'total_tokens': 108, 'completion_tokens_details': {'audio_tokens': None, 'reasoning_tokens': 0}, 'prompt_tokens_details': {'audio_tokens': None, 'cached_tokens': 0}}, 'model_name': 'gpt-4o-mini-2024-07-18', 'system_fingerprint': 'fp_e2bde53e6e', 'finish_reason': 'tool_calls', 'logprobs': None}, id='run-1875182c-5b73-4891-ac97-6abe0988f497-0', tool_calls=[{'name': 'add', 'args': {'a': 2, 'b': 2}, 'id': 'call_SnoZ1WRbaOtflTq1OYwWAzNf', 'type': 'tool_call'}], usage_metadata={'input_tokens': 91, 'output_tokens': 17, 'total_tokens': 108, 'input_token_details': {'cache_read': 0}, 'output_token_details': {'reasoning': 0}}),\n",
       "  ToolMessage(content='4', name='add', id='93d1041a-d26e-4abe-ac63-a2faebda889b', tool_call_id='call_SnoZ1WRbaOtflTq1OYwWAzNf'),\n",
       "  AIMessage(content='2 + 2 equals 4.', additional_kwargs={'refusal': None}, response_metadata={'token_usage': {'completion_tokens': 9, 'prompt_tokens': 116, 'total_tokens': 125, 'completion_tokens_details': {'audio_tokens': None, 'reasoning_tokens': 0}, 'prompt_tokens_details': {'audio_tokens': None, 'cached_tokens': 0}}, 'model_name': 'gpt-4o-mini-2024-07-18', 'system_fingerprint': 'fp_e2bde53e6e', 'finish_reason': 'stop', 'logprobs': None}, id='run-246c0c01-3419-4208-a8d3-f1cbae2c893a-0', usage_metadata={'input_tokens': 116, 'output_tokens': 9, 'total_tokens': 125, 'input_token_details': {'cache_read': 0}, 'output_token_details': {'reasoning': 0}})]}"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "response2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "================================\u001b[1m Human Message \u001b[0m=================================\n",
      "\n",
      "what is 2 +  2\n",
      "None\n",
      "==================================\u001b[1m Ai Message \u001b[0m==================================\n",
      "Tool Calls:\n",
      "  add (call_SnoZ1WRbaOtflTq1OYwWAzNf)\n",
      " Call ID: call_SnoZ1WRbaOtflTq1OYwWAzNf\n",
      "  Args:\n",
      "    a: 2\n",
      "    b: 2\n",
      "None\n",
      "=================================\u001b[1m Tool Message \u001b[0m=================================\n",
      "Name: add\n",
      "\n",
      "4\n",
      "None\n",
      "==================================\u001b[1m Ai Message \u001b[0m==================================\n",
      "\n",
      "2 + 2 equals 4.\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "display_message(response2)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "query = \"what is 2 +  2 and multiply it by 10.\"\n",
    "response3 = graph.invoke({\"messages\":HumanMessage(content=query,role = 'user')})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'messages': [HumanMessage(content='what is 2 +  2 and multiply it by 10.', additional_kwargs={}, response_metadata={}, id='0b34cb0f-6635-4bf6-919c-12fcc7ddbe41', role='user'),\n",
       "  AIMessage(content='', additional_kwargs={'tool_calls': [{'id': 'call_wfZugVjIL5oyf7CszvYJtLml', 'function': {'arguments': '{\"a\": 2, \"b\": 2}', 'name': 'add'}, 'type': 'function'}, {'id': 'call_Ukx2qJ2ZCHT4RW1il8xDoIik', 'function': {'arguments': '{\"a\": 4, \"b\": 10}', 'name': 'multiply'}, 'type': 'function'}], 'refusal': None}, response_metadata={'token_usage': {'completion_tokens': 50, 'prompt_tokens': 98, 'total_tokens': 148, 'completion_tokens_details': {'audio_tokens': None, 'reasoning_tokens': 0}, 'prompt_tokens_details': {'audio_tokens': None, 'cached_tokens': 0}}, 'model_name': 'gpt-4o-mini-2024-07-18', 'system_fingerprint': 'fp_e2bde53e6e', 'finish_reason': 'tool_calls', 'logprobs': None}, id='run-423e6919-efd9-4f62-a7fd-e7adf3567735-0', tool_calls=[{'name': 'add', 'args': {'a': 2, 'b': 2}, 'id': 'call_wfZugVjIL5oyf7CszvYJtLml', 'type': 'tool_call'}, {'name': 'multiply', 'args': {'a': 4, 'b': 10}, 'id': 'call_Ukx2qJ2ZCHT4RW1il8xDoIik', 'type': 'tool_call'}], usage_metadata={'input_tokens': 98, 'output_tokens': 50, 'total_tokens': 148, 'input_token_details': {'cache_read': 0}, 'output_token_details': {'reasoning': 0}}),\n",
       "  ToolMessage(content='4', name='add', id='40a24465-5039-40a1-b288-0db3e181d313', tool_call_id='call_wfZugVjIL5oyf7CszvYJtLml'),\n",
       "  ToolMessage(content='40', name='multiply', id='dd02935f-189f-448f-bc61-6e9d21b66d7c', tool_call_id='call_Ukx2qJ2ZCHT4RW1il8xDoIik'),\n",
       "  AIMessage(content='The result of \\\\(2 + 2\\\\) is \\\\(4\\\\), and when you multiply it by \\\\(10\\\\), the result is \\\\(40\\\\).', additional_kwargs={'refusal': None}, response_metadata={'token_usage': {'completion_tokens': 33, 'prompt_tokens': 164, 'total_tokens': 197, 'completion_tokens_details': {'audio_tokens': None, 'reasoning_tokens': 0}, 'prompt_tokens_details': {'audio_tokens': None, 'cached_tokens': 0}}, 'model_name': 'gpt-4o-mini-2024-07-18', 'system_fingerprint': 'fp_e2bde53e6e', 'finish_reason': 'stop', 'logprobs': None}, id='run-2aad7057-a244-4c25-8d68-210f4e9668bb-0', usage_metadata={'input_tokens': 164, 'output_tokens': 33, 'total_tokens': 197, 'input_token_details': {'cache_read': 0}, 'output_token_details': {'reasoning': 0}})]}"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "response3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "================================\u001b[1m Human Message \u001b[0m=================================\n",
      "\n",
      "what is 2 +  2 and multiply it by 10.\n",
      "None\n",
      "==================================\u001b[1m Ai Message \u001b[0m==================================\n",
      "Tool Calls:\n",
      "  add (call_wfZugVjIL5oyf7CszvYJtLml)\n",
      " Call ID: call_wfZugVjIL5oyf7CszvYJtLml\n",
      "  Args:\n",
      "    a: 2\n",
      "    b: 2\n",
      "  multiply (call_Ukx2qJ2ZCHT4RW1il8xDoIik)\n",
      " Call ID: call_Ukx2qJ2ZCHT4RW1il8xDoIik\n",
      "  Args:\n",
      "    a: 4\n",
      "    b: 10\n",
      "None\n",
      "=================================\u001b[1m Tool Message \u001b[0m=================================\n",
      "Name: add\n",
      "\n",
      "4\n",
      "None\n",
      "=================================\u001b[1m Tool Message \u001b[0m=================================\n",
      "Name: multiply\n",
      "\n",
      "40\n",
      "None\n",
      "==================================\u001b[1m Ai Message \u001b[0m==================================\n",
      "\n",
      "The result of \\(2 + 2\\) is \\(4\\), and when you multiply it by \\(10\\), the result is \\(40\\).\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "display_message(response3)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "now query is = Add 5 to the <code>result</code>\n",
    "\n",
    "As graph don't have access to memory currently it don't what is result here.\n",
    "i.e Ans will be wrong"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "query = \"And Add 5 to the result\"\n",
    "response4 = graph.invoke({\"messages\":HumanMessage(content=query,role = 'user')})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "================================\u001b[1m Human Message \u001b[0m=================================\n",
      "\n",
      "And Add 5 to the result\n",
      "None\n",
      "==================================\u001b[1m Ai Message \u001b[0m==================================\n",
      "Tool Calls:\n",
      "  add (call_ST8eyKt8bg6J7IMwt8sbnqJ1)\n",
      " Call ID: call_ST8eyKt8bg6J7IMwt8sbnqJ1\n",
      "  Args:\n",
      "    a: 5\n",
      "    b: 0\n",
      "None\n",
      "=================================\u001b[1m Tool Message \u001b[0m=================================\n",
      "Name: add\n",
      "\n",
      "5\n",
      "None\n",
      "==================================\u001b[1m Ai Message \u001b[0m==================================\n",
      "\n",
      "The result of adding 5 to 0 is 5.\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "display_message(response4)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# <font color=\"green\">Agent With Memory</font>\n",
    "Giving access to memory to graph."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langgraph.checkpoint.memory import MemorySaver\n",
    "memory = MemorySaver()\n",
    "memory.memory={}  # clearing out any previous saved checkpoint.\n",
    "react_graph_memory = builder.compile(checkpointer=memory)  # calling out graph object to attach memory\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "================================\u001b[1m Human Message \u001b[0m=================================\n",
      "\n",
      "what is 2 multiply 2\n",
      "None\n",
      "==================================\u001b[1m Ai Message \u001b[0m==================================\n",
      "Tool Calls:\n",
      "  multiply (call_8m4tGktkc6esnPSe27y0GuXh)\n",
      " Call ID: call_8m4tGktkc6esnPSe27y0GuXh\n",
      "  Args:\n",
      "    a: 2\n",
      "    b: 2\n",
      "None\n",
      "=================================\u001b[1m Tool Message \u001b[0m=================================\n",
      "Name: multiply\n",
      "\n",
      "4\n",
      "None\n",
      "==================================\u001b[1m Ai Message \u001b[0m==================================\n",
      "\n",
      "2 multiplied by 2 is 4.\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "config = {\"configurable\":{\"thread_id\":1}}\n",
    "query1 = \"what is 2 multiply 2\"\n",
    "response5 = react_graph_memory.invoke({\"messages\":HumanMessage(content=query1,role = 'user')},config=config)\n",
    "display_message(response5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "query2 = \"And Add 10 to the previous esult\"\n",
    "response6 = react_graph_memory.invoke({\"messages\":HumanMessage(content=query2,role = 'user')},config=config)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now it has the access to the memory. As it knows what is previous result."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "================================\u001b[1m Human Message \u001b[0m=================================\n",
      "\n",
      "what is 2 multiply 2\n",
      "None\n",
      "==================================\u001b[1m Ai Message \u001b[0m==================================\n",
      "Tool Calls:\n",
      "  multiply (call_8m4tGktkc6esnPSe27y0GuXh)\n",
      " Call ID: call_8m4tGktkc6esnPSe27y0GuXh\n",
      "  Args:\n",
      "    a: 2\n",
      "    b: 2\n",
      "None\n",
      "=================================\u001b[1m Tool Message \u001b[0m=================================\n",
      "Name: multiply\n",
      "\n",
      "4\n",
      "None\n",
      "==================================\u001b[1m Ai Message \u001b[0m==================================\n",
      "\n",
      "2 multiplied by 2 is 4.\n",
      "None\n",
      "================================\u001b[1m Human Message \u001b[0m=================================\n",
      "\n",
      "And Add 10 to the previous esult\n",
      "None\n",
      "==================================\u001b[1m Ai Message \u001b[0m==================================\n",
      "Tool Calls:\n",
      "  add (call_mI1mJMxHutBOOdGSEpQ6JA5u)\n",
      " Call ID: call_mI1mJMxHutBOOdGSEpQ6JA5u\n",
      "  Args:\n",
      "    a: 4\n",
      "    b: 10\n",
      "None\n",
      "=================================\u001b[1m Tool Message \u001b[0m=================================\n",
      "Name: add\n",
      "\n",
      "14\n",
      "None\n",
      "==================================\u001b[1m Ai Message \u001b[0m==================================\n",
      "\n",
      "Adding 10 to the previous result gives you 14.\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "display_message(response6)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
