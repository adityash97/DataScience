{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "53e4580d-396e-45cd-bac1-cf52b12ce7b9",
   "metadata": {},
   "source": [
    "## Basic Vectorization Approches\n",
    "\n",
    "\n",
    "## One Hot Encoding\n",
    "`pd.get_dummies(dataframe, columns=[<column names>])`\n",
    " It allows the use of categorical variables in models that require numerical input.\n",
    " \n",
    "1. size of vector is directly proposnal to the vocabulary\n",
    "2. More Sparsity\n",
    "3. It treats words as atomic unit and has no notion of dissimilarity between word.Means if there are words `ran , run, apple` the euclidean distance between `ran` and `run` is same as `run` and `apple`\n",
    "4. OOV(out of vocabulary)\n",
    "   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "5591d704-fc3c-4e3c-9aa3-2dd364991c1e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "processed_docs = [\"Dog bites man\",\"Man bites dog.\",\"Dog eats meat.\",\"Man eats food.\"]\n",
    "empdata = pd.read_csv(\"datasets/empdata.csv\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "8bfdc983-5a68-4069-9205-ca4cbe3052f2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>First Name</th>\n",
       "      <th>Gender</th>\n",
       "      <th>Senior Management</th>\n",
       "      <th>Team</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Douglas</td>\n",
       "      <td>Male</td>\n",
       "      <td>True</td>\n",
       "      <td>Marketing</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Thomas</td>\n",
       "      <td>Male</td>\n",
       "      <td>True</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Maria</td>\n",
       "      <td>Female</td>\n",
       "      <td>False</td>\n",
       "      <td>Finance</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Jerry</td>\n",
       "      <td>Male</td>\n",
       "      <td>True</td>\n",
       "      <td>Finance</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Larry</td>\n",
       "      <td>Male</td>\n",
       "      <td>True</td>\n",
       "      <td>Client Services</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  First Name  Gender Senior Management             Team\n",
       "0    Douglas    Male              True        Marketing\n",
       "1     Thomas    Male              True              NaN\n",
       "2      Maria  Female             False          Finance\n",
       "3      Jerry    Male              True          Finance\n",
       "4      Larry    Male              True  Client Services"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "empdata.head()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e4c54efd-8bbd-4540-aa98-33aa65b00179",
   "metadata": {},
   "source": [
    "### Checking unique value in columns and value counts of column data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "225f6e77-a955-4542-83de-a1693ded37eb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Douglas' 'Thomas' 'Maria' 'Jerry' 'Larry' 'Dennis' 'Ruby' nan 'Angela'\n",
      " 'Frances' 'Louise' 'Julie' 'Brandon' 'Gary' 'Kimberly' 'Lillian' 'Jeremy'\n",
      " 'Shawn' 'Diana' 'Donna' 'Lois' 'Matthew' 'Joshua' 'John' 'Craig' 'Scott'\n",
      " 'Terry' 'Benjamin' 'Christina' 'Joyce' 'Jean' 'Theresa' 'Rachel' 'Linda'\n",
      " 'Stephanie' 'Michael' 'Christine' 'Beverly' 'Marilyn' 'Cynthia' 'Roger'\n",
      " 'Bruce' 'Kathy' 'Clarence' 'Chris' 'Nancy' 'Todd' 'Alan' 'Sara' 'Karen'\n",
      " 'Carl' 'Henry' 'Irene' 'Paula' 'Denise' 'Kathleen' 'Steve' 'Jose'\n",
      " 'Johnny' 'Bobby' 'Bonnie' 'Margaret' 'Charles' 'Robin' 'Gerald'\n",
      " 'Christopher' 'Steven' 'Doris' 'Annie' 'Janice' 'James' 'Virginia'\n",
      " 'Harry' 'Heather' 'Laura' 'Tina' 'Harold' 'Melissa' 'Aaron' 'Jack'\n",
      " 'Phyllis' 'Paul' 'Russell' 'Shirley' 'Willie' 'Ashley' 'Pamela' 'Andrea'\n",
      " 'Peter' 'Helen' 'Patricia' 'Michelle' 'William' 'Kenneth' 'Antonio'\n",
      " 'Rebecca' 'Carlos' 'Carolyn' 'Gloria' 'Adam' 'Elizabeth' 'Teresa'\n",
      " 'Nicole' 'Jennifer' 'Philip' 'Patrick' 'Sean' 'Ruth' 'Victor' 'Marie'\n",
      " 'Howard' 'Norma' 'Arthur' 'Mary' 'Wayne' 'Jane' 'Jessica' 'Mark' 'Randy'\n",
      " 'Sandra' 'Carol' 'Barbara' 'Ronald' 'Jonathan' 'Katherine' 'Emily' 'Lisa'\n",
      " 'Evelyn' 'Gregory' 'Billy' 'Jason' 'Daniel' 'Sarah' 'George' 'Diane'\n",
      " 'Kathryn' 'Cheryl' 'Kevin' 'Walter' 'Robert' 'Jimmy' 'Fred' 'Brenda'\n",
      " 'Justin' 'Betty' 'Sharon' 'Ralph' 'Edward' 'Debra' 'Anne' 'Roy' 'Frank'\n",
      " 'Nicholas' 'Judy' 'Tammy' 'Jesse' 'Joan' 'Ernest' 'Jacqueline' 'Jeffrey'\n",
      " 'Samuel' 'Earl' 'Richard' 'Lori' 'Susan' 'Juan' 'Albert' 'Stephen' 'Rose'\n",
      " 'Joe' 'Julia' 'Dorothy' 'Deborah' 'Alice' 'Wanda' 'Lawrence' 'Amy' 'Ryan'\n",
      " 'Judith' 'Eugene' 'Donald' 'Ann' 'Raymond' 'Catherine' 'Amanda' 'Anna'\n",
      " 'Joseph' 'Andrew' 'Kelly' 'Louis' 'Mildred' 'Eric' 'Timothy' 'Anthony'\n",
      " 'Martha' 'Brian' 'Martin' 'Janet' 'Keith' 'Phillip' 'David']\n",
      "lenght =  201\n"
     ]
    }
   ],
   "source": [
    "print(empdata['First Name'].unique())\n",
    "print(\"lenght = \",len(empdata['First Name'].unique()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "b91ad433-5614-4924-a889-39576653f668",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "column name :  First Name\n",
      "['Douglas' 'Thomas' 'Maria' 'Jerry' 'Larry' 'Dennis' 'Ruby' nan 'Angela'\n",
      " 'Frances' 'Louise' 'Julie' 'Brandon' 'Gary' 'Kimberly' 'Lillian' 'Jeremy'\n",
      " 'Shawn' 'Diana' 'Donna' 'Lois' 'Matthew' 'Joshua' 'John' 'Craig' 'Scott'\n",
      " 'Terry' 'Benjamin' 'Christina' 'Joyce' 'Jean' 'Theresa' 'Rachel' 'Linda'\n",
      " 'Stephanie' 'Michael' 'Christine' 'Beverly' 'Marilyn' 'Cynthia' 'Roger'\n",
      " 'Bruce' 'Kathy' 'Clarence' 'Chris' 'Nancy' 'Todd' 'Alan' 'Sara' 'Karen'\n",
      " 'Carl' 'Henry' 'Irene' 'Paula' 'Denise' 'Kathleen' 'Steve' 'Jose'\n",
      " 'Johnny' 'Bobby' 'Bonnie' 'Margaret' 'Charles' 'Robin' 'Gerald'\n",
      " 'Christopher' 'Steven' 'Doris' 'Annie' 'Janice' 'James' 'Virginia'\n",
      " 'Harry' 'Heather' 'Laura' 'Tina' 'Harold' 'Melissa' 'Aaron' 'Jack'\n",
      " 'Phyllis' 'Paul' 'Russell' 'Shirley' 'Willie' 'Ashley' 'Pamela' 'Andrea'\n",
      " 'Peter' 'Helen' 'Patricia' 'Michelle' 'William' 'Kenneth' 'Antonio'\n",
      " 'Rebecca' 'Carlos' 'Carolyn' 'Gloria' 'Adam' 'Elizabeth' 'Teresa'\n",
      " 'Nicole' 'Jennifer' 'Philip' 'Patrick' 'Sean' 'Ruth' 'Victor' 'Marie'\n",
      " 'Howard' 'Norma' 'Arthur' 'Mary' 'Wayne' 'Jane' 'Jessica' 'Mark' 'Randy'\n",
      " 'Sandra' 'Carol' 'Barbara' 'Ronald' 'Jonathan' 'Katherine' 'Emily' 'Lisa'\n",
      " 'Evelyn' 'Gregory' 'Billy' 'Jason' 'Daniel' 'Sarah' 'George' 'Diane'\n",
      " 'Kathryn' 'Cheryl' 'Kevin' 'Walter' 'Robert' 'Jimmy' 'Fred' 'Brenda'\n",
      " 'Justin' 'Betty' 'Sharon' 'Ralph' 'Edward' 'Debra' 'Anne' 'Roy' 'Frank'\n",
      " 'Nicholas' 'Judy' 'Tammy' 'Jesse' 'Joan' 'Ernest' 'Jacqueline' 'Jeffrey'\n",
      " 'Samuel' 'Earl' 'Richard' 'Lori' 'Susan' 'Juan' 'Albert' 'Stephen' 'Rose'\n",
      " 'Joe' 'Julia' 'Dorothy' 'Deborah' 'Alice' 'Wanda' 'Lawrence' 'Amy' 'Ryan'\n",
      " 'Judith' 'Eugene' 'Donald' 'Ann' 'Raymond' 'Catherine' 'Amanda' 'Anna'\n",
      " 'Joseph' 'Andrew' 'Kelly' 'Louis' 'Mildred' 'Eric' 'Timothy' 'Anthony'\n",
      " 'Martha' 'Brian' 'Martin' 'Janet' 'Keith' 'Phillip' 'David']\n",
      "length =  201\n",
      "value Count of column :  First Name\n",
      "Marilyn    11\n",
      "Barbara    10\n",
      "Jeremy     10\n",
      "Todd       10\n",
      "Steven      9\n",
      "           ..\n",
      "Brian       1\n",
      "Jean        1\n",
      "Dennis      1\n",
      "Angela      1\n",
      "David       1\n",
      "Name: count, Length: 200, dtype: int64\n",
      "-------------------------\n",
      "column name :  Gender\n",
      "['Male' 'Female' nan]\n",
      "length =  3\n",
      "value Count of column :  Gender\n",
      "Female    431\n",
      "Male      424\n",
      "Name: count, dtype: int64\n",
      "-------------------------\n",
      "column name :  Senior Management\n",
      "[True False nan]\n",
      "length =  3\n",
      "value Count of column :  Senior Management\n",
      "True     468\n",
      "False    465\n",
      "Name: count, dtype: int64\n",
      "-------------------------\n",
      "column name :  Team\n",
      "['Marketing' nan 'Finance' 'Client Services' 'Legal' 'Product'\n",
      " 'Engineering' 'Business Development' 'Human Resources' 'Sales'\n",
      " 'Distribution']\n",
      "length =  11\n",
      "value Count of column :  Team\n",
      "Client Services         106\n",
      "Finance                 102\n",
      "Business Development    101\n",
      "Marketing                98\n",
      "Product                  95\n",
      "Sales                    94\n",
      "Engineering              92\n",
      "Human Resources          91\n",
      "Distribution             90\n",
      "Legal                    88\n",
      "Name: count, dtype: int64\n",
      "-------------------------\n"
     ]
    }
   ],
   "source": [
    "for column in empdata:\n",
    "    unique_data = empdata[column].unique()\n",
    "    print(\"column name : \", column)\n",
    "    print(unique_data)\n",
    "    print(\"length = \",len(unique_data))\n",
    "    print(\"value Count of column : \",empdata[column].value_counts())\n",
    "    print(\"-\"*25)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3ee93cda-667f-4b17-975f-e14b3f031a9d",
   "metadata": {},
   "source": [
    "### Implementing One hot encoding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "ab32e0b5-762a-49ac-a5e9-c451d13333cf",
   "metadata": {},
   "outputs": [],
   "source": [
    "OHE = pd.get_dummies(empdata, columns=['Gender'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "39099377-8761-474c-afc9-13b1427ca25e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>First Name</th>\n",
       "      <th>Senior Management</th>\n",
       "      <th>Team</th>\n",
       "      <th>Gender_Female</th>\n",
       "      <th>Gender_Male</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Douglas</td>\n",
       "      <td>True</td>\n",
       "      <td>Marketing</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Thomas</td>\n",
       "      <td>True</td>\n",
       "      <td>NaN</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Maria</td>\n",
       "      <td>False</td>\n",
       "      <td>Finance</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Jerry</td>\n",
       "      <td>True</td>\n",
       "      <td>Finance</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Larry</td>\n",
       "      <td>True</td>\n",
       "      <td>Client Services</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>995</th>\n",
       "      <td>Henry</td>\n",
       "      <td>False</td>\n",
       "      <td>Distribution</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>996</th>\n",
       "      <td>Phillip</td>\n",
       "      <td>False</td>\n",
       "      <td>Finance</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>997</th>\n",
       "      <td>Russell</td>\n",
       "      <td>False</td>\n",
       "      <td>Product</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>998</th>\n",
       "      <td>Larry</td>\n",
       "      <td>False</td>\n",
       "      <td>Business Development</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>999</th>\n",
       "      <td>Albert</td>\n",
       "      <td>True</td>\n",
       "      <td>Sales</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1000 rows × 5 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "    First Name Senior Management                  Team  Gender_Female  \\\n",
       "0      Douglas              True             Marketing          False   \n",
       "1       Thomas              True                   NaN          False   \n",
       "2        Maria             False               Finance           True   \n",
       "3        Jerry              True               Finance          False   \n",
       "4        Larry              True       Client Services          False   \n",
       "..         ...               ...                   ...            ...   \n",
       "995      Henry             False          Distribution          False   \n",
       "996    Phillip             False               Finance          False   \n",
       "997    Russell             False               Product          False   \n",
       "998      Larry             False  Business Development          False   \n",
       "999     Albert              True                 Sales          False   \n",
       "\n",
       "     Gender_Male  \n",
       "0           True  \n",
       "1           True  \n",
       "2          False  \n",
       "3           True  \n",
       "4           True  \n",
       "..           ...  \n",
       "995        False  \n",
       "996         True  \n",
       "997         True  \n",
       "998         True  \n",
       "999         True  \n",
       "\n",
       "[1000 rows x 5 columns]"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "OHE\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "6d087fd8-c613-419b-a69a-5d481d8b24b1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>First Name</th>\n",
       "      <th>Senior Management</th>\n",
       "      <th>Team_Business Development</th>\n",
       "      <th>Team_Client Services</th>\n",
       "      <th>Team_Distribution</th>\n",
       "      <th>Team_Engineering</th>\n",
       "      <th>Team_Finance</th>\n",
       "      <th>Team_Human Resources</th>\n",
       "      <th>Team_Legal</th>\n",
       "      <th>Team_Marketing</th>\n",
       "      <th>Team_Product</th>\n",
       "      <th>Team_Sales</th>\n",
       "      <th>Gender_Female</th>\n",
       "      <th>Gender_Male</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Douglas</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Thomas</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Maria</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Jerry</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Larry</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>995</th>\n",
       "      <td>Henry</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>996</th>\n",
       "      <td>Phillip</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>997</th>\n",
       "      <td>Russell</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>998</th>\n",
       "      <td>Larry</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>999</th>\n",
       "      <td>Albert</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1000 rows × 14 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "    First Name Senior Management  Team_Business Development  \\\n",
       "0      Douglas              True                      False   \n",
       "1       Thomas              True                      False   \n",
       "2        Maria             False                      False   \n",
       "3        Jerry              True                      False   \n",
       "4        Larry              True                      False   \n",
       "..         ...               ...                        ...   \n",
       "995      Henry             False                      False   \n",
       "996    Phillip             False                      False   \n",
       "997    Russell             False                      False   \n",
       "998      Larry             False                       True   \n",
       "999     Albert              True                      False   \n",
       "\n",
       "     Team_Client Services  Team_Distribution  Team_Engineering  Team_Finance  \\\n",
       "0                   False              False             False         False   \n",
       "1                   False              False             False         False   \n",
       "2                   False              False             False          True   \n",
       "3                   False              False             False          True   \n",
       "4                    True              False             False         False   \n",
       "..                    ...                ...               ...           ...   \n",
       "995                 False               True             False         False   \n",
       "996                 False              False             False          True   \n",
       "997                 False              False             False         False   \n",
       "998                 False              False             False         False   \n",
       "999                 False              False             False         False   \n",
       "\n",
       "     Team_Human Resources  Team_Legal  Team_Marketing  Team_Product  \\\n",
       "0                   False       False            True         False   \n",
       "1                   False       False           False         False   \n",
       "2                   False       False           False         False   \n",
       "3                   False       False           False         False   \n",
       "4                   False       False           False         False   \n",
       "..                    ...         ...             ...           ...   \n",
       "995                 False       False           False         False   \n",
       "996                 False       False           False         False   \n",
       "997                 False       False           False          True   \n",
       "998                 False       False           False         False   \n",
       "999                 False       False           False         False   \n",
       "\n",
       "     Team_Sales  Gender_Female  Gender_Male  \n",
       "0         False          False         True  \n",
       "1         False          False         True  \n",
       "2         False           True        False  \n",
       "3         False          False         True  \n",
       "4         False          False         True  \n",
       "..          ...            ...          ...  \n",
       "995       False          False        False  \n",
       "996       False          False         True  \n",
       "997       False          False         True  \n",
       "998       False          False         True  \n",
       "999        True          False         True  \n",
       "\n",
       "[1000 rows x 14 columns]"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "OHE1 = pd.get_dummies(empdata, columns=[\"Team\",\"Gender\"])\n",
    "OHE1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "ff3f5b5e-c8a8-455a-aace-530f1b7759d4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>First Name</th>\n",
       "      <th>Senior Management</th>\n",
       "      <th>Team_Business Development</th>\n",
       "      <th>Team_Client Services</th>\n",
       "      <th>Team_Distribution</th>\n",
       "      <th>Team_Engineering</th>\n",
       "      <th>Team_Finance</th>\n",
       "      <th>Team_Human Resources</th>\n",
       "      <th>Team_Legal</th>\n",
       "      <th>Team_Marketing</th>\n",
       "      <th>Team_Product</th>\n",
       "      <th>Team_Sales</th>\n",
       "      <th>Gender_Female</th>\n",
       "      <th>Gender_Male</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Douglas</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Thomas</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Maria</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Jerry</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Larry</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  First Name Senior Management  Team_Business Development  \\\n",
       "0    Douglas              True                      False   \n",
       "1     Thomas              True                      False   \n",
       "2      Maria             False                      False   \n",
       "3      Jerry              True                      False   \n",
       "4      Larry              True                      False   \n",
       "\n",
       "   Team_Client Services  Team_Distribution  Team_Engineering  Team_Finance  \\\n",
       "0                 False              False             False         False   \n",
       "1                 False              False             False         False   \n",
       "2                 False              False             False          True   \n",
       "3                 False              False             False          True   \n",
       "4                  True              False             False         False   \n",
       "\n",
       "   Team_Human Resources  Team_Legal  Team_Marketing  Team_Product  Team_Sales  \\\n",
       "0                 False       False            True         False       False   \n",
       "1                 False       False           False         False       False   \n",
       "2                 False       False           False         False       False   \n",
       "3                 False       False           False         False       False   \n",
       "4                 False       False           False         False       False   \n",
       "\n",
       "   Gender_Female  Gender_Male  \n",
       "0          False         True  \n",
       "1          False         True  \n",
       "2           True        False  \n",
       "3          False         True  \n",
       "4          False         True  "
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "OHE1.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "62afac3c-ba13-4e2e-abb4-5692bab9633a",
   "metadata": {},
   "source": [
    "## Bag Of Words\n",
    "The key idea behind it is as follows: represent the text under consideration as a bag (collec‐ tion) of words while ignoring the order and context. The basic intuition behind it is that it assumes that the text belonging to a given class in the dataset is characterized by a unique set of words. If two text pieces have nearly the same words, then they belong to the same bag (class). Thus, by analyzing the words present in a piece of text, one can identify the class (bag) it belongs to.\n",
    "\n",
    "\n",
    "\n",
    "It overcome the few drawbacks of `OHE` like\n",
    "\n",
    "1. Similar words are clustored together.Which capture some context\n",
    "2. If two documents have similar vocabulary, they’ll be closer to each other in the vector space and vice versa.\n",
    "\n",
    "Drawbacks\n",
    "1. As name says Bag of Words so the order is lost\n",
    "2. OOV\n",
    "3. It does not capture the similarity between different words that mean the same thing. Say we have three documents: “I run”, “I ran”, and “I ate”. BoW vectors of all three documents will be equally apart.\n",
    "\n",
    "`from sklearn.feature_extraction.text import CountVectorizer`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "f04580b3-ae04-4bea-a3b5-ab471a9b8ca2",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "count_vect = CountVectorizer()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "730c4fb3-ecb8-40d1-a49b-164abf330c26",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "bow_rep = count_vect.fit_transform(processed_docs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "26c30a41-7547-4fc0-8758-1e80fc589347",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Our vocabulary:  {'dog': 1, 'bites': 0, 'man': 4, 'eats': 2, 'meat': 5, 'food': 3}\n"
     ]
    }
   ],
   "source": [
    "print(\"Our vocabulary: \", count_vect.vocabulary_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "id": "ee916a0d-7f61-4792-8acf-0b632223fb34",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[1, 1, 0, 0, 1, 0],\n",
       "       [1, 1, 0, 0, 1, 0],\n",
       "       [0, 1, 1, 0, 0, 1],\n",
       "       [0, 0, 1, 1, 1, 0]])"
      ]
     },
     "execution_count": 76,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bow_rep.toarray()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "id": "9d0858f3-2c2a-45b0-8182-e3576d801a97",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "BoW representation for 'dog bites man':  [[1 1 0 0 1 0]]\n"
     ]
    }
   ],
   "source": [
    "print(\"BoW representation for 'dog bites man': \", bow_rep[0].toarray())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "id": "b1d187dd-6620-42bf-b472-5ac1f59e7e4e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "BoW representation for 'man bites dog:  [[1 1 0 0 1 0]]\n"
     ]
    }
   ],
   "source": [
    "print(\"BoW representation for 'man bites dog: \",bow_rep[1].toarray())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "id": "22649f8d-39cc-46ea-8e01-79c8282f6300",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "BoW representation for 'Man eats food.:  [[0 0 1 1 1 0]]\n"
     ]
    }
   ],
   "source": [
    "print(\"BoW representation for 'Man eats food.: \",bow_rep[3].toarray())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "id": "e5515534-05aa-4127-87b0-e4cfac28928e",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Get the representation using this vocabulary, for a new text\n",
    "temp = count_vect.transform([\"dog and dog are friends\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "id": "5e2e4180-ce62-48c2-a8c2-654f59bd7281",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Bow representation for 'dog and dog are friends': [[0 2 0 0 0 0]]\n"
     ]
    }
   ],
   "source": [
    "print(\"Bow representation for 'dog and dog are friends':\",temp.toarray())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3a183b84-5982-45bf-999a-1b0e11da801c",
   "metadata": {},
   "source": [
    "Sometimes, we don’t care about the frequency of occurrence of words in text and we only want to represent whether a word exists in the text or not. Researchers have shown that such a representation without considering fre‐ quency is useful for sentiment analysis.In such cases, we just initialize CountVectorizer with the binary=True option\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "id": "0f7d6ed0-a0f8-491e-8926-464921b5081c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[1, 1, 0, 0, 1, 0],\n",
       "       [1, 1, 0, 0, 1, 0],\n",
       "       [0, 1, 1, 0, 0, 1],\n",
       "       [0, 0, 1, 1, 1, 0]])"
      ]
     },
     "execution_count": 86,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "count_vect = CountVectorizer(binary=True)\n",
    "bow_rep = count_vect.fit_transform(processed_docs)\n",
    "bow_rep.toarray()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "id": "bc6c186e-60fb-48db-9356-90f6330a9bcf",
   "metadata": {},
   "outputs": [],
   "source": [
    "new_text = count_vect.transform(['dog and dog are friends'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "id": "ae0a1c62-74ac-4de3-9186-287c6a2bafae",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0, 1, 0, 0, 0, 0]])"
      ]
     },
     "execution_count": 90,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "new_text.toarray()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b57dd51e-93b8-4370-a394-c4f694719c4c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "d0fc5f74-004c-4973-b705-95c586e38562",
   "metadata": {},
   "source": [
    "### Bag Of N Grams\n",
    "\n",
    "All the representation schemes we’ve seen so far treat words as independent units. There is no notion of phrases or word ordering. The bag-of-n-grams (BoN) approach tries to remedy this. It does so by breaking text into chunks of n contiguous words (or tokens). This can help us capture some context, which earlier approaches could not do. Each chunk is called an n-gram. The corpus vocabulary, V, is then nothing but a collection of all unique n-grams across the text corpus.\n",
    "\n",
    "To elaborate, let’s consider our example corpus. Let’s construct a 2-gram (a.k.a. bigram) model for it. The set of all bigrams in the corpus is as follows: {dog bites, bites man, man bites, bites dog, dog eats, eats meat, man eats, eats food}. Then, BoN representation consists of an eight-dimensional vector for each document. The bigram representation for the first two documents is as follows: D1 : [1,1,0,0,0,0,0,0], D2 : [0,0,1,1,0,0,0,0].\n",
    "\n",
    "pros and cons of BoN:\n",
    "\n",
    "1. It captures some context and word-order information in the form of n-grams.\n",
    "2. As n increases, dimensionality (and therefore sparsity) only increases rapidly.\n",
    "3. oov\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "id": "8de47e31-9873-4454-bf29-3b26117df03c",
   "metadata": {},
   "outputs": [],
   "source": [
    "#n-gram vectorization example with count vectorizer and uni, bi, trigrams\n",
    "bag_n_gram = CountVectorizer(ngram_range=(1,3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "id": "fa4b24c4-8908-4e85-922c-93ea1e6504c4",
   "metadata": {},
   "outputs": [],
   "source": [
    "bow_rep = bag_n_gram.fit_transform(processed_docs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "id": "9b4581e0-96a4-4370-8cb2-59a11b80de88",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Our vocabulary:  {'dog': 3, 'bites': 0, 'man': 12, 'dog bites': 4, 'bites man': 2, 'dog bites man': 5, 'man bites': 13, 'bites dog': 1, 'man bites dog': 14, 'eats': 8, 'meat': 17, 'dog eats': 6, 'eats meat': 10, 'dog eats meat': 7, 'food': 11, 'man eats': 15, 'eats food': 9, 'man eats food': 16}\n"
     ]
    }
   ],
   "source": [
    "#Look at the vocabulary mapping\n",
    "print(\"Our vocabulary: \", bag_n_gram.vocabulary_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "id": "afcc720b-2d21-4a32-97e0-3b1dc978056f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Bow representation for 'dog and dog are friends': [[0 0 0 2 0 0 0 0 0 0 0 0 0 0 0 0 0 0]]\n"
     ]
    }
   ],
   "source": [
    "#Get the representation using this vocabulary, for a new text\n",
    "temp = bag_n_gram.transform([\"dog and dog are friends\"])\n",
    "print(\"Bow representation for 'dog and dog are friends':\", temp.toarray())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "id": "625f8698-9a3b-4e9a-8d91-9ab1133fce4e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "18"
      ]
     },
     "execution_count": 121,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(temp.toarray()[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bfc7e0b7-2752-4c5e-a612-a74b43c47a8a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "2273088d-63e8-4d24-94f4-94bc1b8f68ee",
   "metadata": {},
   "source": [
    "### TF-IDF(Term Frequency - Inverse Document Frequency)\n",
    "In all the three approaches weve seen so far, all the words in the text are treated as equally important—there’s \n",
    "no notion of some words in the document being more important than others. TF-IDF, or term frequency–inverse document frequency, \n",
    "addresses this issue. It aims to quantify the importance of a given word relative to other words in the document and in the corpus.\n",
    "It’s a commonly used representation scheme for information-retrieval systems, for extracting relevant documents from a corpus for \n",
    "a given text query.\n",
    "\"The intuition behind TF-IDF is as follows: if a word w appears many times in a docu‐ ment di but does not occur much in the rest of the documents dj in the corpus, then the word w must be of great importance to the document di. The importance of w should increase in proportion to its frequency in di, but at the same time, its impor‐ tance should decrease in proportion to the word’s frequency in other documents dj in the corpus. Mathematically, this is captured using two quantities: TF and IDF. The two are then combined to arrive at the TF-IDF score.\"\n",
    "\n",
    "TF (term frequency) measures how often a term or word occurs in a given document. Since different documents in the corpus may be of different lengths, a term may occur more often in a longer document as compared to a shorter document. To nor‐ malize these counts, we divide the number of occurrences by the length of the docu‐ ment. TF of a term t in a document d is defined as: TF t, d = Number of occurrences of term t in document d Total number of terms in the document d\"\n",
    "\n",
    "\n",
    "IDF (inverse document frequency) measures the importance of the term across a cor‐ pus. In computing TF, all terms are given equal importance (weightage). However, it’s a well-known fact that stop words like is, are, am, etc., are not important, even though they occur frequently. To account for such cases, IDF weighs down the terms that are very common across a corpus and weighs up the rare terms. IDF of a term t is calcu‐ lated as follows:\n",
    "IDF t = loge Total number of documents in the corpus Number of documents with term t in them\n",
    "\n",
    "The TF-IDF score is a product of these two terms. Thus, TF-IDF score = TF * IDF\n",
    "\n",
    "\n",
    "TF-IDF is better than the vectorization methods we saw earlier in terms of capturing similarities between words, it still suffers from the curse of high dimensionality."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 141,
   "id": "687cb3fb-5369-4a3b-a0dd-23c122f281ae",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "tfidf =  TfidfVectorizer()\n",
    "bow_rep_tfidf = tfidf.fit_transform(processed_docs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 142,
   "id": "65b9a788-7b67-41e4-bdfc-27402dbc2b2e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1.51082562 1.22314355 1.51082562 1.91629073 1.22314355 1.91629073]\n"
     ]
    }
   ],
   "source": [
    "print(tfidf.idf_) #IDF for all words in the vocabulary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 148,
   "id": "575b1abb-a8e4-49e2-9edb-9bf1b19860a4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['bites' 'dog' 'eats' 'food' 'man' 'meat']\n"
     ]
    }
   ],
   "source": [
    "print(tfidf.get_feature_names_out()) #All words in the vocabulary."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ed43e67c-35b7-43fc-bd80-ed407a92faae",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 149,
   "id": "6e41e8a2-56cc-410c-9683-fad3773bc302",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tfidf representation for 'dog and man are friends':\n",
      " [[0.         0.70710678 0.         0.         0.70710678 0.        ]]\n"
     ]
    }
   ],
   "source": [
    "temp = tfidf.transform([\"dog and man are friends\"])\n",
    "print(\"Tfidf representation for 'dog and man are friends':\\n\", temp.toarray())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "883f17d2-dbd6-4244-a7e6-901879447eaf",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "0a22dae0-4f48-49ec-a075-fd7362fffcd5",
   "metadata": {},
   "source": [
    "### If we look back at all the representation schemes we’ve discussed so far, we notice three fundamental drawbacks:\n",
    "1. They’re discrete representations—i.e., they treat language units (words, n-grams, etc.) as atomic units. This discreteness hampers their ability to capture relation‐ ships between words.\n",
    "2.  The feature vectors are sparse and high-dimensional representations. The dimen‐ sionality increases with the size of the vocabulary, with most values being zero for any vector. This hampers learning capability. Further, high-dimensionality representation makes them computationally inefficient.\n",
    "3.  They cannot handle OOV words.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "32234d73-d5c5-4c8a-99e4-6fcd2b654375",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
